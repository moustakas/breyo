#!/usr/bin/env python

"""Pipeline-reduce a single night of Breyo imaging.


"""
import os, glob, time
import numpy as np
from astropy.io import fits



rootdir = '/content/drive/My Drive/Teaching/Astro/380-F19'
datadir = os.path.join('{}'.format(rootdir), 'Stellar Photometry Data')
reduxdir = os.path.join('{}'.format(rootdir), 'Stellar Photometry Data - Reduced')
if not os.path.isdir(reduxdir):
    os.makedirs(reduxdir, exist_ok=True)

"""Decide here whether to rerun certain steps of the pipeline."""

"""Write a little display script that we'll use throughout."""

def display_image(img, minclip=5, maxclip=95, label=None, cmap='Greys_r', 
                  srcs=None, projection=None, calibrated=False):
    """Simple wrapper to display an image.
    
    """
    from astropy.visualization import AsinhStretch as Stretch
    from astropy.visualization import ZScaleInterval as Interval
    from astropy.visualization.mpl_normalize import ImageNormalize

    #from astropy.visualization import simple_norm
    #norm = simple_norm(img, min_percent=minclip, max_percent=maxclip)

    interval = Interval(contrast=0.5)
    vmin, vmax = interval.get_limits(img)
    norm = ImageNormalize(interval=interval, stretch=Stretch(a=0.9))

    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw={'projection': projection})
    im = ax.imshow(img, origin='lower', norm=norm, cmap=cmap,
                   vmin=vmin, vmax=vmax)
    if projection:
        ax.coords.grid(color='red')
        ax.coords['ra'].set_axislabel('Right Ascension')
        ax.coords['dec'].set_axislabel('Declination')      
    else:
        ax.set_xlabel('Column Number (pixels)')
        ax.set_ylabel('Row Number (pixels)')

    # Mark the locations of stars.
    if srcs:
        from photutils import CircularAperture
        pos = np.transpose((srcs['xcentroid'], srcs['ycentroid']))
        aps = CircularAperture(pos, r=12.)
        aps.plot(color='red', lw=1.5, alpha=0.6, axes=ax)
      
    # Make room for the colorbar
    fig.subplots_adjust(right=0.8)
    cax = fig.add_axes([0.85, 0.28, 0.05, 0.45])
    c = plt.colorbar(im, cax=cax)
    if label:
        c.set_label(label)
    else:
        if calibrated:
            c.set_label(r'Intensity ($e^{-}/s$)')
        else:
            c.set_label('Intensity (ADU)')

"""## Create calibration files if they don't already exist.

Build the master bias frames and flat-fields.
"""

def make_masterbias(overwrite=False):
    masterbiasfile = os.path.join(reduxdir, 'master-bias.fits')
    if not os.path.isfile(masterbiasfile) or overwrite:
        print('Building the master bias frame.')
        allbiasfiles = glob.glob('{}/bias-????.fit'.format(datadir))
        # build the median stack
        allbias = np.array([fits.getdata(biasfile) for biasfile in allbiasfiles])
        masterbias = np.median(allbias, axis=0)
        # read one header and write out
        hdr = fits.getheader(allbiasfiles[0])
        hdr['NBIAS'] = len(allbias)
        print('Writing {}'.format(masterbiasfile))
        fits.writeto(masterbiasfile, masterbias.astype('f4'), header=hdr, overwrite=True)
    else:
        print('Reading {}'.format(masterbiasfile))
        masterbias = fits.getdata(masterbiasfile)
    return masterbias

def make_masterflat(masterbias, overwrite=False):
    allmasterflat = []
    for filt in ('b', 'v', 'r'):
        masterflatfile = os.path.join(reduxdir, 'master-flat-{}.fits'.format(filt))
        if not os.path.isfile(masterflatfile) or overwrite:
            print('Working on filter {}'.format(filt))
            # Get the filenames.
            allflatfiles = glob.glob('{}/skyflat-????{}.fit'.format(datadir, filt))
            # Read the data, one image at a time and normalize by the mean counts.
            allflat = []
            for flatfile in allflatfiles:
                print('  Reading {}'.format(flatfile))
                thisflat = fits.getdata(flatfile) * 1.0 # convert to float
                thisflat -= masterbias
                thisflat /= np.median(thisflat)
                allflat.append(thisflat)
            # median stack
            thismasterflat = np.median(allflat, axis=0)
            # read one header and write out
            hdr = fits.getheader(allflatfiles[0])
            hdr['NFLAT'] = len(allflat)
            print('Writing {}'.format(masterflatfile))
            fits.writeto(masterflatfile, thismasterflat.astype('f4'), header=hdr, overwrite=True)
        else:
            print('Reading {}'.format(masterflatfile))
            thismasterflat = fits.getdata(masterflatfile)
        allmasterflat.append(thismasterflat)
    return allmasterflat

# Commented out IPython magic to ensure Python compatibility.
# %time masterbias = make_masterbias(overwrite=do_masterbias)

# Commented out IPython magic to ensure Python compatibility.
# %time masterflat_b, masterflat_v, masterflat_r = make_masterflat(masterbias, overwrite=do_masterflats)

"""### Reduce the data!

Reduce all the science data by subtracting the bias and dividing by the flat-field (in the appropriate filter).
"""

def reduce_alldata(bias, bflat, vflat, rflat, prefix='fb', overwrite=False):
    t0 = time.time()
    allimgfiles = glob.glob('{}/NGC6830-*.fit'.format(datadir))
    print('Found {} images in {}'.format(len(allimgfiles), datadir))
    for imgfile in allimgfiles:
        imgoutfile = os.path.join(reduxdir, '{}-{}'.format(prefix, os.path.basename(imgfile).replace('.fit', '.fits')))
        if not os.path.isfile(imgoutfile) or overwrite:
            img = fits.getdata(imgfile) * 1.0 # convert to float
            # Subtract the bias and then divide by the appropriate flat-field
            img -= bias
            hdr = fits.getheader(imgfile)
            filt = hdr['FILTER'].lower().strip()
            if filt == 'blue':
                img /= bflat
            elif filt == 'green':
                img /= vflat
            elif filt == 'red':
                img /= rflat
            else:
                print('Unrecognized filter {}!'.format(filt))
            # Trim the first 100 columns, which are funky.
            img = img[:, 100:]
            # Finally multiply by the gain and divide by the exposure time.
            img = img * hdr['EGAIN'] / hdr['EXPTIME'] # [e-/sec]
            print('Writing {}'.format(imgoutfile))
            fits.writeto(imgoutfile, img.astype('f4'), header=hdr, overwrite=True)
    print('All done in {:.2f} sec'.format(time.time() - t0))

# Commented out IPython magic to ensure Python compatibility.
# %time reduce_alldata(bias=masterbias, bflat=masterflat_b, vflat=masterflat_v, rflat=masterflat_r, overwrite=do_reduce_alldata)

"""### Astrometrically calibrate the data.

"Astrometry" is the process of determining *where* your data are pointing, i.e.,figuring out the transformation matrix between pixel coordinates (x,y) and celestial coordinates (RA,Dec), which has a long, rich history.  In a nutshell, this transformation matrix is determined by comparing the *observed* positions of stars (or other reference sources) against their *known* positions (i.e., using an external, calibrated catalog).

Needless to say there are many intricacies involved in astrometry, which I encourage you to delve into.  But for now we can proceed with just the basics and use the [astrometry.net](http://astrometry.net) engine to determine the astrometric solution of our data.

Let's start by reading a single reduced image.
"""

imgfile = os.path.join('{}'.format(reduxdir), 'fb-NGC6830-0002v.fits')
print('Reading {}'.format(imgfile))
img, hdr = fits.getdata(imgfile, header=True)
#display_image(img)

"""First, we need the *observed* positions of the stars in this image, but in order to detect those stars we first have to model and subtract the *sky background* from the data.

We'll build the sky background by measuring the median pixel value in a "low-resolution" mesh grid, which we will then interpolate onto the original resolution of the image.  For additional details see the **photutils** tutorial on [Background Estimation](https://photutils.readthedocs.io/en/stable/background.html).
"""

def get_sky_background(img, verbose=True):
    from astropy.stats import SigmaClip
    from photutils import Background2D, MedianBackground
    sigma_clip = SigmaClip(sigma=3.)
    bkg = Background2D(img, (100, 100), filter_size=(5, 5), sigma_clip=sigma_clip, 
                       bkg_estimator=MedianBackground())
    if verbose:
        print('Sky background median = {:.3f}, rms = {:.3f} ADU.'.format(bkg.background_median, bkg.background_rms_median))
    return bkg

# Commented out IPython magic to ensure Python compatibility.
# %time bkg = get_sky_background(img, verbose=True)

"""Now let's visualize the original data, the background model, and the background-subtracted image."""

img_nosky = img - bkg.background

display_image(img)
display_image(bkg.background)
display_image(img_nosky)

def qa_background():
    med, sig = bkg.background_median, bkg.background_rms_median
    vrange = (-3*sig, med+5*sig)
    fig, ax = plt.subplots(figsize=(7, 5))
    _ = ax.hist(img.flatten(), bins=100, range=vrange, label='Image w/ Background')
    #_ = ax.hist(bkg.background.flatten(), bins=50, range=(-sig, med+5*sig), label='Background')
    _ = ax.hist(img_nosky.flatten(), bins=100, range=vrange, label='Image w/o Background')
    ax.axvline(x=bkg.background_median, lw=2, ls='-', color='k')
    ax.set_xlabel('Intensity (ADU)')
    ax.set_ylabel('Number')
    ax.legend(fontsize=12, frameon=False)

qa_background()

"""Next, let's find all the point sources (i.e., stars) in the image above a threshold value of the background rms.  Also write out the file for future use."""

def find_stars(image, imgfile, fwhm=3.0, nsigma=3, sigma=None, 
               verbose=True, overwrite=False):
    from astropy.table import Table
    
    starsfile = os.path.join(reduxdir, 'stars-{}'.format(os.path.basename(imgfile)))
    if not os.path.isfile(starsfile) or overwrite:
        from photutils import DAOStarFinder
        if sigma is None:
            sigma = np.std(image)

        daofind = DAOStarFinder(fwhm=fwhm, threshold=nsigma * sigma)
        srcs = daofind(image)
        # reverse-sort by flux 
        srcs.sort('flux')
        srcs.reverse()
        if verbose:
            print('Found {} sources'.format(len(srcs)))

        print('Writing {} stars to {}'.format(len(srcs), starsfile))
        srcs.write(starsfile, overwrite=True)
    else:
        srcs = Table.read(starsfile)
        print('Read {} stars from {}'.format(len(srcs), starsfile))
    return srcs

srcs = find_stars(img_nosky, imgfile, sigma=bkg.background_rms_median, nsigma=5, 
                  verbose=True, overwrite=do_calib_stars)
srcs

"""Visualize the image again with the detected sources overlaid."""

display_image(img_nosky, srcs=srcs, calibrated=True)

"""Now we're ready to find the astrometric solution by uploading our table of sources (actually, their *x,y* positions) to **astrometry.net**, which returns a FITS header with the transformation matrix we need / want.  For this next step you'll need your **astrometry.net** API key, which you can find (if you're logged in) [here](http://nova.astrometry.net/api_help).

Please do not use my API key!
"""

def get_astrometry(imgfile, srcs=None, api_key=None, prefix='w', overwrite=False):
    from astropy.io import fits
    import astropy.units as u
    from astropy.coordinates import SkyCoord
    from astroquery.astrometry_net import AstrometryNet  

    wcsfile = os.path.join(reduxdir, '{}{}'.format(prefix, os.path.basename(imgfile)))
    if not os.path.isfile(wcsfile) or overwrite:
        img, hdr = fits.getdata(imgfile, header=True)

        # Initialize the API.
        ast = AstrometryNet()
        if api_key:
            ast.api_key = api_key
        #ast.show_allowed_settings()

        # Get the initial position center based on the header.
        c = SkyCoord(hdr['OBJCTRA']+hdr['OBJCTDEC'], unit=(u.hourangle, u.deg))
        print('Initial RA, Dec = {:.5f}, {:.5f}'.format(c.ra.value, c.dec.value))

        # Query the astrometry.net engine!
        t0 = time.time()
        wcshdr = ast.solve_from_source_list(
            srcs['xcentroid'], srcs['ycentroid'], hdr['naxis1'], hdr['naxis2'],
            center_ra=c.ra.value, center_dec=c.dec.value, radius=15/60.0, 
            scale_type='ev', scale_est=0.8, scale_err=10, scale_units='arcsecperpix',
            crpix_center=True)
        print('Total time = {:.3f} min'.format((time.time() - t0)/60))

        # update the original header
        for key in wcshdr.keys():
            if key not in hdr and key != 'COMMENT' and key != 'HISTORY':
                hdr[key] = wcshdr[key]

        print('Writing {}'.format(wcsfile))
        fits.writeto(wcsfile, img, header=wcshdr, overwrite=True)        
    else:
        wcshdr = fits.getheader(wcsfile)

    return wcsfile, wcshdr

"""Getting the solution will take a little time, but you can monitor the results by navigating to [nova.astrometry.net](http://nova.astrometry.net). Be patient!"""

# Commented out IPython magic to ensure Python compatibility.
my_api = 'qmadkihbafggctcf'
# %time wcsfile, wcshdr = get_astrometry(imgfile, srcs, api_key=my_api, overwrite=do_astrometry)
wcshdr

"""For fun, let's do one more step and project/map/interpolate the original (i.e., distorted) image onto an undistorted tangent plane and then visualize it!"""

def undistort_image(imgfile, wcsfile, pixscale=0.8, display=False):
    """Little wrapper script to project (i.e., undistort) a distorted 
    image onto a tangent plane.
    
    """
    from astropy.io import fits
    from astropy.wcs import WCS
    from reproject import reproject_interp
    
    img, hdr = fits.getdata(imgfile, header=True)
    wcshdr = fits.getheader(wcsfile)

    # Create a header describing a tangent plane.
    for key in ('WCSAXES', 'CTYPE1', 'CTYPE2', 'EQUINOX', 'LONPOLE', 'LATPOLE', 
                'CRVAL1', 'CRVAL2', 'CRPIX1', 'CRPIX2', 'CUNIT1', 'CUNIT2',
                'CD1_1', 'CD1_2', 'CD2_1', 'CD2_2', 'IMAGEW', 'IMAGEH'):
        hdr[key] = wcshdr[key]

    # Tangent projection
    #wwcshdr = WCS(wcshdr)
    #whdr = WCS(hdr)    
    #whdr.all_world2pix(wwcshdr.all_pix2world(np.array([(1, 1), (1, dim[0]), (dim[1], dim[0]), (dim[1], 0)]), 1), 1)
    hdr['CTYPE1'] = 'RA---TAN'
    hdr['CTYPE2'] = 'DEC--TAN'
    # update the pixel scale [arcsec/pix] to the desired constant with 
    # no rotation
    hdr['CD1_2'] = 0.0
    hdr['CD2_1'] = 0.0
    hdr['CD1_1'] = -pixscale / 3600.0
    hdr['CD2_2'] =  pixscale / 3600.0

    # now project
    img_proj, footprint = reproject_interp((img, wcshdr), hdr)

    if display:
        #display_image(img, projection=WCS(wcshdr))
        display_image(img_proj, projection=WCS(hdr))

    return img_proj, footprint

img_proj, footprint = undistort_image(imgfile, wcsfile, pixscale=0.8, display=True)

"""### Photometrically calibrate the data.

The last step we will do here is to photometrically calibrate the data.  Remember that our images are in units of counts or ADU, but in order to do (astro)physics, we need to convert these counts (really, the count *rate*, ADU/s) to physical units like flux density, erg/s/cm2/Hz.

We will do our photometric calibration by correlating the sources we've detected against an *existing* catalog which already has been calibrated, in order to derive the **zeropoint** for our image.  Then we will apply the mean zeropoint, accounting for our exposure time and atmospheric extinction, in order to create final calibrated image.

For demonstration purposes, let's again focus on a single image.  We'll read the reduced image and the astrometric header.
"""

def read_one_image():
    from astropy.table import Table
    from astropy.wcs import WCS

    # Hack!
    imgfile = os.path.join('{}'.format(reduxdir), 'fb-NGC6830-0002v.fits')
    hdrfile = os.path.join('{}'.format(reduxdir), 'wfb-NGC6830-0002v.fits')
    starsfile = os.path.join('{}'.format(reduxdir), 'stars-fb-NGC6830-0002v.fits')

    print('Reading {}'.format(imgfile))
    img, hdr = fits.getdata(imgfile, header=True)
    wcshdr = fits.getheader(hdrfile)
    imgwcs = WCS(wcshdr)#, naxis=2)

    #print('Reading {}'.format(starsfile))
    #srcs = Table.read(starsfile)

    return img, hdr, imgwcs

img, hdr, imgwcs = read_one_image()
#display_image(img, calibrated=True)

"""Retrieve a catalog of reference stars."""

def find_stars(image, imgfile, fwhm=3.0, nsigma=3, sigma=None, 
               verbose=True, overwrite=False):
    from astropy.table import Table
    
    starsfile = os.path.join(reduxdir, 'stars-{}'.format(os.path.basename(imgfile)))
    if not os.path.isfile(starsfile) or overwrite:
        from photutils import DAOStarFinder
        if sigma is None:
            sigma = np.std(image)

        daofind = DAOStarFinder(fwhm=fwhm, threshold=nsigma * sigma)
        srcs = daofind(image)
        # reverse-sort by flux 
        srcs.sort('flux')
        srcs.reverse()
        if verbose:
            print('Found {} sources'.format(len(srcs)))

        print('Writing {} stars to {}'.format(len(srcs), starsfile))
        srcs.write(starsfile, overwrite=True)
    else:
        srcs = Table.read(starsfile)
        print('Read {} stars from {}'.format(len(srcs), starsfile))
    return srcs

def get_panstarrs_catalog(imgwcs, imgfile, radius=0.2, rfaint=17, region=False):
    from astroquery.mast import Catalogs
    ra0, dec0 = imgwcs.wcs.crval
    print('Querying Pan-STARRS catalog with radius={:.3f} deg and central coordinates RA,Dec={:.5f},{:.5f}'.format(
        radius, ra0, dec0))
    if region:
        allcat = Catalogs.query_region('{} {}'.format(ra0, dec0), radius=radius,
                                       catalog='PANSTARRS', data_release='dr2', 
                                       table='mean')#, rMeanPSFMag=[12, 22])
    else:
        allcat = Catalogs.query_criteria(coordinates='{} {}'.format(ra0, dec0), radius=radius,
                                         catalog='PANSTARRS', data_release='dr2', 
                                         table='mean',
                                         columns=['objID', 'raMean', 'decMean',
                                                  'gMeanPSFMag', 'rMeanPSFMag', 'iMeanPSFMag', 'zMeanPSFMag'],
                                         gMeanPSFMag=[('lte', 18), ('gte', 12)],
                                         rMeanPSFMag=[('lte', 18), ('gte', 12)],
                                         iMeanPSFMag=[('lte', 18), ('gte', 12)],
                                         zMeanPSFMag=[('lte', 18), ('gte', 12)],
                                         sort_by=[("asc", "rMeanPSFMag")])
    
    #rmag = allcat['rMeanPSFMag']
    #good = np.isfinite(rmag) * rmag < rfaint
    #cat = allcat[good]
    #print('Keeping {}/{} Pan-STARRS sources.'.format(len(cat), len(allcat)))
    return allcat

# Commented out IPython magic to ensure Python compatibility.
# %time refcat = get_panstarrs_catalog(imgwcs, radius=0.3)
refcat

"""Let's study the distribution of separations to figure out the correct matching radius."""

import astropy.units as u
from astropy.coordinates import SkyCoord

radec_stars = imgwcs.all_pix2world(srcs['xcentroid']+1, srcs['ycentroid']+1, 1)
refcoord = SkyCoord(ra=refcat['raMean']*u.deg, dec=refcat['decMean']*u.deg)
coord = SkyCoord(ra=radec_stars[0]*u.deg, dec=radec_stars[1]*u.deg)
_, sep2d, _ = coord.match_to_catalog_sky(refcoord)

_ = plt.hist(sep2d.arcsec, bins=100, range=(-0.5, 3))

"""Visualize the location of the matching stars."""

rad = 2 * u.arcsec
indx_ref, indx, d2d, _ = coord.search_around_sky(refcoord, rad)
nmatch = len(indx_ref)
print('Found {}/{} stars within {}'.format(nmatch, len(srcs), rad))
display_image(img, srcs=srcs[indx], calibrated=True)

"""Now let's construct the zeropoint for this image using these reference stars."""

kext = {'Blue': 0.4, 'Green': 0.2, 'Red': 0.1}

import numpy.ma as ma

instmag = srcs['mag'][indx].data - 0.4 * hdr['AIRMASS'] * kext[hdr['FILTER']]
#ps_g = refcat['gMeanPSFMag'][indx_ref].data
ps_r = refcat['rMeanPSFMag'][indx_ref].data
#ps_i = refcat['iMeanPSFMag'][indx_ref].data
#ps_z = refcat['zMeanPSFMag'][indx_ref].data

medzp = np.median(ps_r - instmag)
print(hdr['FILTER'], medzp)

_ = plt.hist(ps_r - instmag, bins=50)
plt.axvline(x=medzp, lw=3, color='k')

def main():
    """
    do_masterbias = False
    do_masterflats = False
    do_reduce_alldata = False
    do_calib_stars = False
    do_astrometry = False
    do_ref_stars = False
    do_photometry = False

    """
    parser = argparse.ArgumentParser()
    parser.add_argument('--masterbias', action='store_true', help='Build the master bias frame.')
    args = parser.parse_args()

    if args.masterbias:
        



if __name__ == '__main__':
    main()
