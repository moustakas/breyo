#!/usr/bin/env python

"""Pipeline-reduce a single night of Breyo imaging.


"""
import os, glob, time, pdb
import argparse

import numpy as np
import astropy.io.fits
import astropy.units as u
from astropy.nddata import CCDData

import ccdproc as ccdp
from ccdproc import ImageFileCollection

imtype2 = {'light': 'Light Frame',
          'dark': 'Dark Frame',
          'flat': 'Flat Field',
          'bias': 'Bias Frame'}
    
imtype = {'Light Frame': 'object',
          'Dark Frame': 'dark',
          'Flat Field': 'flat',
          'Bias Frame': 'bias'}

newfilt = {'Blue': 'B',
           'Green': 'V',
           'Red': 'R',
           'OIII': 'OIII',
           'Ha': 'Ha'}

#from astropy.io import fits
#
#
## Commented out IPython magic to ensure Python compatibility.
## %time reduce_alldata(bias=masterbias, bflat=masterflat_b, vflat=masterflat_v, rflat=masterflat_r, overwrite=do_reduce_alldata)
#
#"""### Astrometrically calibrate the data.
#
#"Astrometry" is the process of determining *where* your data are pointing, i.e.,figuring out the transformation matrix between pixel coordinates (x,y) and celestial coordinates (RA,Dec), which has a long, rich history.  In a nutshell, this transformation matrix is determined by comparing the *observed* positions of stars (or other reference sources) against their *known* positions (i.e., using an external, calibrated catalog).
#
#Needless to say there are many intricacies involved in astrometry, which I encourage you to delve into.  But for now we can proceed with just the basics and use the [astrometry.net](http://astrometry.net) engine to determine the astrometric solution of our data.
#
#Let's start by reading a single reduced image.
#"""
#
#imgfile = os.path.join('{}'.format(reduxdir), 'fb-NGC6830-0002v.fits')
#print('Reading {}'.format(imgfile))
#img, hdr = fits.getdata(imgfile, header=True)
##display_image(img)
#
#"""First, we need the *observed* positions of the stars in this image, but in order to detect those stars we first have to model and subtract the *sky background* from the data.
#
#We'll build the sky background by measuring the median pixel value in a "low-resolution" mesh grid, which we will then interpolate onto the original resolution of the image.  For additional details see the **photutils** tutorial on [Background Estimation](https://photutils.readthedocs.io/en/stable/background.html).
#"""
#
## Commented out IPython magic to ensure Python compatibility.
## %time bkg = get_sky_background(img, verbose=True)
#
#"""Now let's visualize the original data, the background model, and the background-subtracted image."""
#
#img_nosky = img - bkg.background
#
#display_image(img)
#display_image(bkg.background)
#display_image(img_nosky)
#
#qa_background()
#
#"""Next, let's find all the point sources (i.e., stars) in the image above a threshold value of the background rms.  Also write out the file for future use."""
#
#srcs = find_stars(img_nosky, imgfile, sigma=bkg.background_rms_median, nsigma=5, 
#                  verbose=True, overwrite=do_calib_stars)
#srcs
#
#"""Getting the solution will take a little time, but you can monitor the results by navigating to [nova.astrometry.net](http://nova.astrometry.net). Be patient!"""
#
## Commented out IPython magic to ensure Python compatibility.
#my_api = 'qmadkihbafggctcf'
## %time wcsfile, wcshdr = get_astrometry(imgfile, srcs, api_key=my_api, overwrite=do_astrometry)
#wcshdr
#
#"""For fun, let's do one more step and project/map/interpolate the original (i.e., distorted) image onto an undistorted tangent plane and then visualize it!"""
#
#img_proj, footprint = undistort_image(imgfile, wcsfile, pixscale=0.8, display=True)
#
#"""### Photometrically calibrate the data.
#
#The last step we will do here is to photometrically calibrate the data.  Remember that our images are in units of counts or ADU, but in order to do (astro)physics, we need to convert these counts (really, the count *rate*, ADU/s) to physical units like flux density, erg/s/cm2/Hz.
#
#We will do our photometric calibration by correlating the sources we've detected against an *existing* catalog which already has been calibrated, in order to derive the **zeropoint** for our image.  Then we will apply the mean zeropoint, accounting for our exposure time and atmospheric extinction, in order to create final calibrated image.
#
#For demonstration purposes, let's again focus on a single image.  We'll read the reduced image and the astrometric header.
#"""
#
#def read_one_image():
#    from astropy.table import Table
#    from astropy.wcs import WCS
#
#    # Hack!
#    imgfile = os.path.join('{}'.format(reduxdir), 'fb-NGC6830-0002v.fits')
#    hdrfile = os.path.join('{}'.format(reduxdir), 'wfb-NGC6830-0002v.fits')
#    starsfile = os.path.join('{}'.format(reduxdir), 'stars-fb-NGC6830-0002v.fits')
#
#    print('Reading {}'.format(imgfile))
#    img, hdr = fits.getdata(imgfile, header=True)
#    wcshdr = fits.getheader(hdrfile)
#    imgwcs = WCS(wcshdr)#, naxis=2)
#
#    #print('Reading {}'.format(starsfile))
#    #srcs = Table.read(starsfile)
#
#    return img, hdr, imgwcs
#
#img, hdr, imgwcs = read_one_image()
##display_image(img, calibrated=True)
#
#"""Retrieve a catalog of reference stars."""
#
## Commented out IPython magic to ensure Python compatibility.
## %time refcat = get_panstarrs_catalog(imgwcs, radius=0.3)
#refcat
#
#kext = {'Blue': 0.4, 'Green': 0.2, 'Red': 0.1}
#
#import numpy.ma as ma
#
#instmag = srcs['mag'][indx].data - 0.4 * hdr['AIRMASS'] * kext[hdr['FILTER']]
##ps_g = refcat['gMeanPSFMag'][indx_ref].data
#ps_r = refcat['rMeanPSFMag'][indx_ref].data
##ps_i = refcat['iMeanPSFMag'][indx_ref].data
##ps_z = refcat['zMeanPSFMag'][indx_ref].data
#
#medzp = np.median(ps_r - instmag)
#print(hdr['FILTER'], medzp)
#
#_ = plt.hist(ps_r - instmag, bins=50)
#plt.axvline(x=medzp, lw=3, color='k')

def main():
    """
    do_masterbias = False
    do_masterflats = False
    do_reduce_alldata = False
    do_calib_stars = False
    do_astrometry = False
    do_ref_stars = False
    do_photometry = False

    """
    parser = argparse.ArgumentParser()
    parser.add_argument('night', type=str, help='Specify the night to reduce.')
    parser.add_argument('--preproc', action='store_true', help='Preprocess the raw data.')
    parser.add_argument('--masterbias', action='store_true', help='Build the master bias frame.')
    parser.add_argument('--verbose', action='store_true', help='Be verbose.')
    parser.add_argument('--overwrite', action='store_true', help='Overwrite existing files.')
    args = parser.parse_args()

    rawdir = os.path.join(os.getenv('BREYO_DATA_DIR'), 'raw', args.night)
    reduxdir = os.path.join(os.getenv('BREYO_DATA_DIR'), 'reduced', args.night)
    if not os.path.isdir(reduxdir):
        os.makedirs(reduxdir, exist_ok=True)

    if args.preproc:
        ic = ccdp.ImageFileCollection(rawdir, keywords='*', glob_include='*.fit*')
        print('Parsing {} files in {}'.format(len(ic.files), rawdir))
        if args.verbose:
            ic.summary['file', 'imagetyp', 'filter', 'exptime', 'naxis1', 'naxis2']

        #for fname in ic.files:
        for exp, fname in ic.hdus(return_fname=True):
            #if exp.header['NAXIS2'] < 1000: #
            rawfile = os.path.join(rawdir, fname)
            outfile = os.path.join(reduxdir, fname.replace('.fit', '.fits'))
            if os.path.isfile(outfile) or not args.overwrite:
                print('Skipping existing file {}'.format(outfile))
            else:
                hdr = exp.header
                img = CCDData(data=exp.data.astype('f4'), meta=hdr, unit=u.adu)

                # update the header
                #hdr = astropy.io.fits.getheader(rawfile)
                hdr['IMAGETYP'] = imtype[hdr['IMAGETYP']]
                hdr['FILTER'] = newfilt[hdr['FILTER']]

                # ToDo: generalize the trim and add a header card
                img = img[:, 50:]

                print('Writing {}'.format(outfile))
                img.write(outfile, overwrite=True)

        pdb.set_trace()

    if args.masterbias:
        biasfiles = ic.files_filtered(imagetyp=ccdkeyword['bias'], include_path=True)
        pdb.set_trace()

        masterbias = ccdproc.combine(biasfiles, method='average', sigma_clip=True, unit=u.adu)
        
        gaincorrected_master_bias = ccdproc.gain_correct(master_bias,float(gain))
        print('writing fits file for master bias')
        gaincorrected_master_bias.write('bias-combined.fits',overwrite=True)


if __name__ == '__main__':
    main()
